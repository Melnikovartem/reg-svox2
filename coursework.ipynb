{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dO4oLwmLBezL"
   },
   "source": [
    "# Опять переустонавливать Conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1644757573749,
     "user": {
      "displayName": "Артем Мельников",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3u21bfj3xbUWHLdTdT6sP-k0huGdxWfq9GMsmJQ=s64",
      "userId": "12648836304799801100"
     },
     "user_tz": -180
    },
    "id": "bOS0_Y662KrX",
    "outputId": "017c5a3d-b527-4c73-fb25-7cdf600fbdf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 31 03:38:41 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA RTX A4000    Off  | 00000000:02:00.0 Off |                  Off |\r\n",
      "| 30%   31C    P0    N/A / 140W |      0MiB / 16376MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kB21rOnhB32D"
   },
   "source": [
    "# Обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 284,
     "status": "aborted",
     "timestamp": 1644758568119,
     "user": {
      "displayName": "Артем Мельников",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3u21bfj3xbUWHLdTdT6sP-k0huGdxWfq9GMsmJQ=s64",
      "userId": "12648836304799801100"
     },
     "user_tz": -180
    },
    "id": "0az9mi2pkzGB"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import gc\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from os import path\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import svox2\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1644758444593,
     "user": {
      "displayName": "Артем Мельников",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3u21bfj3xbUWHLdTdT6sP-k0huGdxWfq9GMsmJQ=s64",
      "userId": "12648836304799801100"
     },
     "user_tz": -180
    },
    "id": "-CfgECOmNWux",
    "outputId": "0bfceffd-2226-4e75-a170-72e626826a73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/artem/Desktop/coursework/svox2/opt\n"
     ]
    }
   ],
   "source": [
    "%cd svox2/opt\n",
    "from util.dataset import datasets\n",
    "from util.util import get_expon_lr_func, generate_dirs_equirect, viridis_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62,
     "status": "ok",
     "timestamp": 1644758444595,
     "user": {
      "displayName": "Артем Мельников",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3u21bfj3xbUWHLdTdT6sP-k0huGdxWfq9GMsmJQ=s64",
      "userId": "12648836304799801100"
     },
     "user_tz": -180
    },
    "id": "qnWB9fdqJthS",
    "outputId": "92a32345-8eaf-4906-f39d-687789d1b875"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artem/.conda/envs/plenoxel/lib/python3.8/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "PATH = \"/root/reg-svox2\" # \"/home/artem/Desktop/coursework\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "  \"data_dir\": PATH + \"/nerf_synthetic/hotdog\",\n",
    "  \"config\": None,\n",
    "  \"dataset_type\": \"auto\",\n",
    "  \"scene_scale\": None,\n",
    "  \"scale\": None,\n",
    "  \"seq_id\": 1000,\n",
    "  \"epoch_size\": 12800,\n",
    "  \"white_bkgd\": True,\n",
    "  \"llffhold\": 8,\n",
    "  \"normalize_by_bbox\": False,\n",
    "  \"data_bbox_scale\": 1.2,\n",
    "  \"cam_scale_factor\": 0.95,\n",
    "  \"normalize_by_camera\": True,\n",
    "  \"perm\": False,\n",
    "  \"step_size\": 0.5,\n",
    "  \"sigma_thresh\": 1e-08,\n",
    "  \"stop_thresh\": 1e-07,\n",
    "  \"background_brightness\": 1.0,\n",
    "  \"renderer_backend\": \"cuvol\",\n",
    "  \"random_sigma_std\": 0.0,\n",
    "  \"random_sigma_std_background\": 0.0,\n",
    "  \"near_clip\": 0.0,\n",
    "  \"use_spheric_clip\": False,\n",
    "  \"enable_random\": False,\n",
    "  \"last_sample_opaque\": False,\n",
    "  \"train_dir\": PATH + \"ckpt\",\n",
    "  \"reso\": [[128, 128, 128], [512, 512, 512]], #[128, 128, 128], [[128, 128, 128], [256, 256, 256], [384, 384, 384], [512, 512, 512]]\n",
    "  \"upsamp_every\": 38400, \n",
    "  \"init_iters\": 0,\n",
    "  \"upsample_density_add\": 0.0,\n",
    "  \"basis_type\": \"sh\",\n",
    "  \"basis_reso\": 32,\n",
    "  \"sh_dim\": 9,\n",
    "  \"mlp_posenc_size\": 4,\n",
    "  \"mlp_width\": 32,\n",
    "  \"background_nlayers\": 0,\n",
    "  \"background_reso\": 512,\n",
    "  \"n_iters\": 128000,\n",
    "  \"batch_size\": 5000,\n",
    "  \"sigma_optim\": \"rmsprop\",\n",
    "  \"lr_sigma\": 30.0,\n",
    "  \"lr_sigma_final\": 0.05,\n",
    "  \"lr_sigma_decay_steps\": 250000,\n",
    "  \"lr_sigma_delay_steps\": 15000,\n",
    "  \"lr_sigma_delay_mult\": 0.01,\n",
    "  \"sh_optim\": \"rmsprop\",\n",
    "  \"lr_sh\": 0.01,\n",
    "  \"lr_sh_final\": 5e-06,\n",
    "  \"lr_sh_decay_steps\": 250000,\n",
    "  \"lr_sh_delay_steps\": 0,\n",
    "  \"lr_sh_delay_mult\": 0.01,\n",
    "  \"lr_fg_begin_step\": 0,\n",
    "  \"bg_optim\": \"rmsprop\",\n",
    "  \"lr_sigma_bg\": 3.0,\n",
    "  \"lr_sigma_bg_final\": 0.003,\n",
    "  \"lr_sigma_bg_decay_steps\": 250000,\n",
    "  \"lr_sigma_bg_delay_steps\": 0,\n",
    "  \"lr_sigma_bg_delay_mult\": 0.01,\n",
    "  \"lr_color_bg\": 0.1,\n",
    "  \"lr_color_bg_final\": 5e-06,\n",
    "  \"lr_color_bg_decay_steps\": 250000,\n",
    "  \"lr_color_bg_delay_steps\": 0,\n",
    "  \"lr_color_bg_delay_mult\": 0.01,\n",
    "  \"basis_optim\": \"rmsprop\",\n",
    "  \"lr_basis\": 1e-06,\n",
    "  \"lr_basis_final\": 1e-06,\n",
    "  \"lr_basis_decay_steps\": 250000,\n",
    "  \"lr_basis_delay_steps\": 0,\n",
    "  \"lr_basis_begin_step\": 0,\n",
    "  \"lr_basis_delay_mult\": 0.01,\n",
    "  \"rms_beta\": 0.95,\n",
    "  \"print_every\": 20,\n",
    "  \"save_every\": 5,\n",
    "  \"eval_every\": 1,\n",
    "  \"init_sigma\": 0.1,\n",
    "  \"init_sigma_bg\": 0.1,\n",
    "  \"log_mse_image\": False,\n",
    "  \"log_depth_map\": False,\n",
    "  \"log_depth_map_use_thresh\": None,\n",
    "  \"thresh_type\": \"weight\",\n",
    "  \"weight_thresh\": 0.256,\n",
    "  \"density_thresh\": 5.0,\n",
    "  \"background_density_thresh\": 1.000000001,\n",
    "  \"max_grid_elements\": 44000000,\n",
    "  \"tune_mode\": False,\n",
    "  \"tune_nosave\": False,\n",
    "  \"lambda_tv\": 1e-05,\n",
    "  \"tv_sparsity\": 0.01,\n",
    "  \"tv_logalpha\": False,\n",
    "  \"lambda_tv_sh\": 0.001,\n",
    "  \"tv_sh_sparsity\": 0.01,\n",
    "  \"lambda_tv_lumisphere\": 0.0,\n",
    "  \"tv_lumisphere_sparsity\": 0.01,\n",
    "  \"tv_lumisphere_dir_factor\": 0.0,\n",
    "  \"tv_decay\": 1.0,\n",
    "  \"lambda_l2_sh\": 0.0,\n",
    "  \"tv_early_only\": 1,\n",
    "  \"tv_contiguous\": 1,\n",
    "  \"lambda_sparsity\": 0.0,\n",
    "  \"lambda_beta\": 0.0,\n",
    "  \"lambda_tv_background_sigma\": 0.01,\n",
    "  \"lambda_tv_background_color\": 0.01,\n",
    "  \"tv_background_sparsity\": 0.01,\n",
    "  \"lambda_tv_basis\": 0.0,\n",
    "  \"weight_decay_sigma\": 1.0,\n",
    "  \"weight_decay_sh\": 1.0,\n",
    "  \"lr_decay\": True,\n",
    "  \"n_train\": None,\n",
    "  \"nosphereinit\": False,\n",
    "    \n",
    "    \"crop\": 1.0, \n",
    "    \"ray_len\": False, \n",
    "    \"no_vid\": False,\n",
    "    \"no_imsave\": False, \n",
    "    \n",
    "  \"n_images\": 10,\n",
    "  \"lambda_depth\": 1.0,\n",
    "}\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "    \n",
    "args = dotdict(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41815,
     "status": "ok",
     "timestamp": 1644758486351,
     "user": {
      "displayName": "Артем Мельников",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3u21bfj3xbUWHLdTdT6sP-k0huGdxWfq9GMsmJQ=s64",
      "userId": "12648836304799801100"
     },
     "user_tz": -180
    },
    "id": "AXmZ_Kp2JOvV",
    "outputId": "3216e9d8-4456-4425-d78c-85ae39c7ff81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to extended NSVF dataset\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "'/home/artem/Desktop/coursework/nerf_synthetic/hotdog' is not a directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 2\u001b[0m dset \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m               \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m               \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m               \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m               \u001b[49m\u001b[43mfactor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfactor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m               \u001b[49m\u001b[43mn_images\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m dset_test \u001b[38;5;241m=\u001b[39m datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m](args\u001b[38;5;241m.\u001b[39mdata_dir, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/coursework/svox2/opt/util/dataset.py:20\u001b[0m, in \u001b[0;36mauto_dataset\u001b[0;34m(root, *args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefaulting to extended NSVF dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNSVFDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/coursework/svox2/opt/util/nsvf_dataset.py:51\u001b[0m, in \u001b[0;36mNSVFDataset.__init__\u001b[0;34m(self, root, split, epoch_size, device, scene_scale, factor, scale, permutation, white_bkgd, normalize_by_bbox, data_bbox_scale, cam_scale_factor, normalize_by_camera, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     35\u001b[0m     root,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     49\u001b[0m ):\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(root), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not a directory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scene_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m         scene_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: '/home/artem/Desktop/coursework/nerf_synthetic/hotdog' is not a directory"
     ]
    }
   ],
   "source": [
    "factor = 1\n",
    "dset = datasets[args.dataset_type](\n",
    "               args.data_dir,\n",
    "               split=\"train\",\n",
    "               device=device,\n",
    "               factor=factor,\n",
    "               n_images = args.n_images)\n",
    "dset_test = datasets[\"auto\"](args.data_dir, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "executionInfo": {
     "elapsed": 9502,
     "status": "error",
     "timestamp": 1644758568138,
     "user": {
      "displayName": "Артем Мельников",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3u21bfj3xbUWHLdTdT6sP-k0huGdxWfq9GMsmJQ=s64",
      "userId": "12648836304799801100"
     },
     "user_tz": -180
    },
    "id": "cw-_pnyOEjoV",
    "outputId": "4ccb971c-4592-48ca-d766-9aefb8f13b9a"
   },
   "outputs": [],
   "source": [
    "reso_list = args.reso\n",
    "reso_id = 0\n",
    "\n",
    "grid = svox2.SparseGrid(reso=reso_list[reso_id],\n",
    "                        center=dset.scene_center,\n",
    "                        radius=dset.scene_radius,\n",
    "                        use_sphere_bound=dset.use_sphere_bound, \n",
    "                        basis_dim=9,\n",
    "                        use_z_order=True,\n",
    "                        device=device,\n",
    "                        basis_reso=32,\n",
    "                        basis_type=svox2.__dict__['BASIS_TYPE_' + args.basis_type.upper()], #['sh', '3d_texture', 'mlp']\n",
    "                        mlp_posenc_size=4,\n",
    "                        mlp_width=32,\n",
    "                        background_nlayers=0,\n",
    "                        background_reso=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 264,
     "status": "aborted",
     "timestamp": 1644758568099,
     "user": {
      "displayName": "Артем Мельников",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3u21bfj3xbUWHLdTdT6sP-k0huGdxWfq9GMsmJQ=s64",
      "userId": "12648836304799801100"
     },
     "user_tz": -180
    },
    "id": "ZaBy--ZGM1wz"
   },
   "outputs": [],
   "source": [
    "grid.sh_data.data[:] = 0.0\n",
    "grid.density_data.data[:] = 0.0 if args.lr_fg_begin_step > 0 else args.init_sigma\n",
    "\n",
    "if grid.use_background:\n",
    "    grid.background_data.data[..., -1] = args.init_sigma_bg\n",
    "if grid.basis_type == svox2.BASIS_TYPE_3D_TEXTURE:\n",
    "    grid.reinit_learned_bases(init_type='sh')\n",
    "elif grid.basis_type == svox2.BASIS_TYPE_MLP:\n",
    "    optim_basis_mlp = torch.optim.Adam(\n",
    "                    grid.basis_mlp.parameters(),\n",
    "                    lr=args.lr_basis\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 274,
     "status": "aborted",
     "timestamp": 1644758568109,
     "user": {
      "displayName": "Артем Мельников",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3u21bfj3xbUWHLdTdT6sP-k0huGdxWfq9GMsmJQ=s64",
      "userId": "12648836304799801100"
     },
     "user_tz": -180
    },
    "id": "tVc57M06iIJV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Render options RenderOptions(backend='cuvol', background_brightness=1.0, step_size=0.5, sigma_thresh=1e-10, stop_thresh=1e-07, last_sample_opaque=False, near_clip=0.0, use_spheric_clip=False, random_sigma_std=1.0, random_sigma_std_background=1.0)\n"
     ]
    }
   ],
   "source": [
    "grid.requires_grad_(True)\n",
    "print('Render options', grid.opt)\n",
    "\n",
    "gstep_id_base = 0\n",
    "resample_cameras = [\n",
    "        svox2.Camera(c2w.to(device=device),\n",
    "                     dset.intrins.get('fx', i),\n",
    "                     dset.intrins.get('fy', i),\n",
    "                     dset.intrins.get('cx', i),\n",
    "                     dset.intrins.get('cy', i),\n",
    "                     width=dset.get_image_size(i)[1],\n",
    "                     height=dset.get_image_size(i)[0],\n",
    "                     ndc_coeffs=dset.ndc_coeffs) for i, c2w in enumerate(dset.c2w)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "aborted",
     "timestamp": 1644758568115,
     "user": {
      "displayName": "Артем Мельников",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3u21bfj3xbUWHLdTdT6sP-k0huGdxWfq9GMsmJQ=s64",
      "userId": "12648836304799801100"
     },
     "user_tz": -180
    },
    "id": "j1-McN5TjL76"
   },
   "outputs": [],
   "source": [
    "summary_writer = SummaryWriter(PATH + \"/ckpt/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 295,
     "status": "aborted",
     "timestamp": 1644758568130,
     "user": {
      "displayName": "Артем Мельников",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3u21bfj3xbUWHLdTdT6sP-k0huGdxWfq9GMsmJQ=s64",
      "userId": "12648836304799801100"
     },
     "user_tz": -180
    },
    "id": "xuwj_Rqa5fLS"
   },
   "outputs": [],
   "source": [
    "ckpt_path = PATH + \"/ckpt/ckpt.npz\"\n",
    "\n",
    "lr_sigma_func = get_expon_lr_func(args.lr_sigma, args.lr_sigma_final, args.lr_sigma_delay_steps,\n",
    "                                  args.lr_sigma_delay_mult, args.lr_sigma_decay_steps)\n",
    "lr_sh_func = get_expon_lr_func(args.lr_sh, args.lr_sh_final, args.lr_sh_delay_steps,\n",
    "                               args.lr_sh_delay_mult, args.lr_sh_decay_steps)\n",
    "lr_basis_func = get_expon_lr_func(args.lr_basis, args.lr_basis_final, args.lr_basis_delay_steps,\n",
    "                               args.lr_basis_delay_mult, args.lr_basis_decay_steps)\n",
    "lr_sigma_bg_func = get_expon_lr_func(args.lr_sigma_bg, args.lr_sigma_bg_final, args.lr_sigma_bg_delay_steps,\n",
    "                               args.lr_sigma_bg_delay_mult, args.lr_sigma_bg_decay_steps)\n",
    "lr_color_bg_func = get_expon_lr_func(args.lr_color_bg, args.lr_color_bg_final, args.lr_color_bg_delay_steps,\n",
    "                               args.lr_color_bg_delay_mult, args.lr_color_bg_decay_steps)\n",
    "lr_sigma_factor = 1.0\n",
    "lr_sh_factor = 1.0\n",
    "lr_basis_factor = 1.0\n",
    "\n",
    "last_upsamp_step = args.init_iters\n",
    "\n",
    "epoch_id = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 299,
     "status": "aborted",
     "timestamp": 1644758568135,
     "user": {
      "displayName": "Артем Мельников",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3u21bfj3xbUWHLdTdT6sP-k0huGdxWfq9GMsmJQ=s64",
      "userId": "12648836304799801100"
     },
     "user_tz": -180
    },
    "id": "WP6JNRZGhwZD"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mdset\u001b[49m\u001b[38;5;241m.\u001b[39mshuffle_rays()\n\u001b[1;32m      3\u001b[0m     epoch_id \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      4\u001b[0m     epoch_size \u001b[38;5;241m=\u001b[39m dset\u001b[38;5;241m.\u001b[39mrays\u001b[38;5;241m.\u001b[39morigins\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dset' is not defined"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    dset.shuffle_rays()\n",
    "    epoch_id += 1\n",
    "    epoch_size = dset.rays.origins.size(0)\n",
    "    batches_per_epoch = (epoch_size-1)//args.batch_size+1\n",
    "    # Test\n",
    "    def eval_step():\n",
    "        # Put in a function to avoid memory leak\n",
    "        print('Eval step')\n",
    "        with torch.no_grad():\n",
    "            stats_test = {'psnr' : 0.0, 'mse' : 0.0}\n",
    "\n",
    "            # Standard set\n",
    "            N_IMGS_TO_EVAL = min(20 if epoch_id > 0 else 5, dset_test.n_images)\n",
    "            N_IMGS_TO_SAVE = N_IMGS_TO_EVAL # if not args.tune_mode else 1\n",
    "            img_eval_interval = dset_test.n_images // N_IMGS_TO_EVAL\n",
    "            img_save_interval = (N_IMGS_TO_EVAL // N_IMGS_TO_SAVE)\n",
    "            img_ids = range(0, dset_test.n_images, img_eval_interval)\n",
    "\n",
    "            # Special 'very hard' specular + fuzz set\n",
    "            #  img_ids = [2, 5, 7, 9, 21,\n",
    "            #             44, 45, 47, 49, 56,\n",
    "            #             80, 88, 99, 115, 120,\n",
    "            #             154]\n",
    "            #  img_save_interval = 1\n",
    "\n",
    "            n_images_gen = 0\n",
    "            for i, img_id in tqdm(enumerate(img_ids), total=len(img_ids)):\n",
    "                c2w = dset_test.c2w[img_id].to(device=device)\n",
    "                cam = svox2.Camera(c2w,\n",
    "                                   dset_test.intrins.get('fx', img_id),\n",
    "                                   dset_test.intrins.get('fy', img_id),\n",
    "                                   dset_test.intrins.get('cx', img_id),\n",
    "                                   dset_test.intrins.get('cy', img_id),\n",
    "                                   width=dset_test.get_image_size(img_id)[1],\n",
    "                                   height=dset_test.get_image_size(img_id)[0],\n",
    "                                   ndc_coeffs=dset_test.ndc_coeffs)\n",
    "                rgb_pred_test = grid.volume_render_image(cam, use_kernel=True)\n",
    "                rgb_gt_test = dset_test.gt[img_id].to(device=device)\n",
    "                all_mses = ((rgb_gt_test - rgb_pred_test) ** 2).cpu()\n",
    "                if i % img_save_interval == 0:\n",
    "                    img_pred = rgb_pred_test.cpu()\n",
    "                    img_pred.clamp_max_(1.0)\n",
    "                    summary_writer.add_image(f'test/image_{img_id:04d}',\n",
    "                            img_pred, global_step=gstep_id_base, dataformats='HWC')\n",
    "                    if args.log_mse_image:\n",
    "                        mse_img = all_mses / all_mses.max()\n",
    "                        summary_writer.add_image(f'test/mse_map_{img_id:04d}',\n",
    "                                mse_img, global_step=gstep_id_base, dataformats='HWC')\n",
    "                    if args.log_depth_map:\n",
    "                        depth_img = grid.volume_render_depth_image(cam,\n",
    "                                    args.log_depth_map_use_thresh if\n",
    "                                    args.log_depth_map_use_thresh else None\n",
    "                                )\n",
    "                        depth_img = viridis_cmap(depth_img.cpu())\n",
    "                        summary_writer.add_image(f'test/depth_map_{img_id:04d}',\n",
    "                                depth_img,\n",
    "                                global_step=gstep_id_base, dataformats='HWC')\n",
    "\n",
    "                rgb_pred_test = rgb_gt_test = None\n",
    "                mse_num : float = all_mses.mean().item()\n",
    "                psnr = -10.0 * math.log10(mse_num)\n",
    "                if math.isnan(psnr):\n",
    "                    print('NAN PSNR', i, img_id, mse_num)\n",
    "                    assert False\n",
    "                stats_test['mse'] += mse_num\n",
    "                stats_test['psnr'] += psnr\n",
    "                n_images_gen += 1\n",
    "\n",
    "            if grid.basis_type == svox2.BASIS_TYPE_3D_TEXTURE or \\\n",
    "               grid.basis_type == svox2.BASIS_TYPE_MLP:\n",
    "                 # Add spherical map visualization\n",
    "                EQ_RESO = 256\n",
    "                eq_dirs = generate_dirs_equirect(EQ_RESO * 2, EQ_RESO)\n",
    "                eq_dirs = torch.from_numpy(eq_dirs).to(device=device).view(-1, 3)\n",
    "\n",
    "                if grid.basis_type == svox2.BASIS_TYPE_MLP:\n",
    "                    sphfuncs = grid._eval_basis_mlp(eq_dirs)\n",
    "                else:\n",
    "                    sphfuncs = grid._eval_learned_bases(eq_dirs)\n",
    "                sphfuncs = sphfuncs.view(EQ_RESO, EQ_RESO*2, -1).permute([2, 0, 1]).cpu().numpy()\n",
    "\n",
    "                stats = [(sphfunc.min(), sphfunc.mean(), sphfunc.max())\n",
    "                        for sphfunc in sphfuncs]\n",
    "                sphfuncs_cmapped = [viridis_cmap(sphfunc) for sphfunc in sphfuncs]\n",
    "                for im, (minv, meanv, maxv) in zip(sphfuncs_cmapped, stats):\n",
    "                    cv2.putText(im, f\"{minv=:.4f} {meanv=:.4f} {maxv=:.4f}\", (10, 20),\n",
    "                                0, 0.5, [255, 0, 0])\n",
    "                sphfuncs_cmapped = np.concatenate(sphfuncs_cmapped, axis=0)\n",
    "                summary_writer.add_image(f'test/spheric',\n",
    "                        sphfuncs_cmapped, global_step=gstep_id_base, dataformats='HWC')\n",
    "                # END add spherical map visualization\n",
    "\n",
    "            stats_test['mse'] /= n_images_gen\n",
    "            stats_test['psnr'] /= n_images_gen\n",
    "            for stat_name in stats_test:\n",
    "                summary_writer.add_scalar('test/' + stat_name,\n",
    "                        stats_test[stat_name], global_step=gstep_id_base)\n",
    "            summary_writer.add_scalar('epoch_id', float(epoch_id), global_step=gstep_id_base)\n",
    "            print('eval stats:', stats_test)\n",
    "    if epoch_id % max(factor, args.eval_every) == 0: #and (epoch_id > 0 or not args.tune_mode):\n",
    "        # NOTE: we do an eval sanity check, if not in tune_mode\n",
    "        eval_step()\n",
    "        gc.collect()\n",
    "\n",
    "    def train_step():\n",
    "        print('Train step')\n",
    "        pbar = tqdm(enumerate(range(0, epoch_size, args.batch_size)), total=batches_per_epoch)\n",
    "        stats = {\"mse\" : 0.0, \"psnr\" : 0.0, \"invsqr_mse\" : 0.0}\n",
    "        for iter_id, batch_begin in pbar:\n",
    "            gstep_id = iter_id + gstep_id_base\n",
    "            if args.lr_fg_begin_step > 0 and gstep_id == args.lr_fg_begin_step:\n",
    "                grid.density_data.data[:] = args.init_sigma\n",
    "            lr_sigma = lr_sigma_func(gstep_id) * lr_sigma_factor\n",
    "            lr_sh = lr_sh_func(gstep_id) * lr_sh_factor\n",
    "            lr_basis = lr_basis_func(gstep_id - args.lr_basis_begin_step) * lr_basis_factor\n",
    "            lr_sigma_bg = lr_sigma_bg_func(gstep_id - args.lr_basis_begin_step) * lr_basis_factor\n",
    "            lr_color_bg = lr_color_bg_func(gstep_id - args.lr_basis_begin_step) * lr_basis_factor\n",
    "            if not args.lr_decay:\n",
    "                lr_sigma = args.lr_sigma * lr_sigma_factor\n",
    "                lr_sh = args.lr_sh * lr_sh_factor\n",
    "                lr_basis = args.lr_basis * lr_basis_factor\n",
    "\n",
    "            batch_end = min(batch_begin + args.batch_size, epoch_size)\n",
    "            batch_origins = dset.rays.origins[batch_begin: batch_end]\n",
    "            batch_dirs = dset.rays.dirs[batch_begin: batch_end]\n",
    "            rgb_gt = dset.rays.gt[batch_begin: batch_end]\n",
    "            print(rgb_gt.shape, rgb_gt)\n",
    "            return\n",
    "            rays = svox2.Rays(batch_origins, batch_dirs)\n",
    "\n",
    "            #  with Timing(\"volrend_fused\"):\n",
    "            rgb_pred = grid.volume_render_fused(rays, rgb_gt,\n",
    "                    beta_loss=args.lambda_beta,\n",
    "                    sparsity_loss=args.lambda_sparsity,\n",
    "                    randomize=args.enable_random)\n",
    "\n",
    "            #  with Timing(\"loss_comp\"):\n",
    "            mse = F.mse_loss(rgb_gt, rgb_pred)\n",
    "\n",
    "            # Stats\n",
    "            mse_num : float = mse.detach().item()\n",
    "            psnr = -10.0 * math.log10(mse_num)\n",
    "            stats['mse'] += mse_num\n",
    "            stats['psnr'] += psnr\n",
    "            stats['invsqr_mse'] += 1.0 / mse_num ** 2\n",
    "\n",
    "            if (iter_id + 1) % args.print_every == 0:\n",
    "                # Print averaged stats\n",
    "                pbar.set_description(f'epoch {epoch_id} psnr={psnr:.2f}')\n",
    "                for stat_name in stats:\n",
    "                    stat_val = stats[stat_name] / args.print_every\n",
    "                    summary_writer.add_scalar(stat_name, stat_val, global_step=gstep_id)\n",
    "                    stats[stat_name] = 0.0\n",
    "                #  if args.lambda_tv > 0.0:\n",
    "                #      with torch.no_grad():\n",
    "                #          tv = grid.tv(logalpha=args.tv_logalpha, ndc_coeffs=dset.ndc_coeffs)\n",
    "                #      summary_writer.add_scalar(\"loss_tv\", tv, global_step=gstep_id)\n",
    "                #  if args.lambda_tv_sh > 0.0:\n",
    "                #      with torch.no_grad():\n",
    "                #          tv_sh = grid.tv_color()\n",
    "                #      summary_writer.add_scalar(\"loss_tv_sh\", tv_sh, global_step=gstep_id)\n",
    "                #  with torch.no_grad():\n",
    "                #      tv_basis = grid.tv_basis() #  summary_writer.add_scalar(\"loss_tv_basis\", tv_basis, global_step=gstep_id)\n",
    "                summary_writer.add_scalar(\"lr_sh\", lr_sh, global_step=gstep_id)\n",
    "                summary_writer.add_scalar(\"lr_sigma\", lr_sigma, global_step=gstep_id)\n",
    "                if grid.basis_type == svox2.BASIS_TYPE_3D_TEXTURE:\n",
    "                    summary_writer.add_scalar(\"lr_basis\", lr_basis, global_step=gstep_id)\n",
    "                if grid.use_background:\n",
    "                    summary_writer.add_scalar(\"lr_sigma_bg\", lr_sigma_bg, global_step=gstep_id)\n",
    "                    summary_writer.add_scalar(\"lr_color_bg\", lr_color_bg, global_step=gstep_id)\n",
    "\n",
    "                if args.weight_decay_sh < 1.0:\n",
    "                    grid.sh_data.data *= args.weight_decay_sigma\n",
    "                if args.weight_decay_sigma < 1.0:\n",
    "                    grid.density_data.data *= args.weight_decay_sh\n",
    "\n",
    "            #  # For outputting the % sparsity of the gradient\n",
    "            #  indexer = grid.sparse_sh_grad_indexer\n",
    "            #  if indexer is not None:\n",
    "            #      if indexer.dtype == torch.bool:\n",
    "            #          nz = torch.count_nonzero(indexer)\n",
    "            #      else:\n",
    "            #          nz = indexer.size()\n",
    "            #      with open(os.path.join(args.train_dir, 'grad_sparsity.txt'), 'a') as sparsity_file:\n",
    "            #          sparsity_file.write(f\"{gstep_id} {nz}\\n\")\n",
    "\n",
    "            # Apply TV/Sparsity regularizers\n",
    "            if args.lambda_tv > 0.0:\n",
    "                #  with Timing(\"tv_inpl\"):\n",
    "                grid.inplace_tv_grad(grid.density_data.grad,\n",
    "                        scaling=args.lambda_tv,\n",
    "                        sparse_frac=args.tv_sparsity,\n",
    "                        logalpha=args.tv_logalpha,\n",
    "                        ndc_coeffs=dset.ndc_coeffs,\n",
    "                        contiguous=args.tv_contiguous)\n",
    "            if args.lambda_tv_sh > 0.0:\n",
    "                #  with Timing(\"tv_color_inpl\"):\n",
    "                grid.inplace_tv_color_grad(grid.sh_data.grad,\n",
    "                        scaling=args.lambda_tv_sh,\n",
    "                        sparse_frac=args.tv_sh_sparsity,\n",
    "                        ndc_coeffs=dset.ndc_coeffs,\n",
    "                        contiguous=args.tv_contiguous)\n",
    "            if args.lambda_tv_lumisphere > 0.0:\n",
    "                grid.inplace_tv_lumisphere_grad(grid.sh_data.grad,\n",
    "                        scaling=args.lambda_tv_lumisphere,\n",
    "                        dir_factor=args.tv_lumisphere_dir_factor,\n",
    "                        sparse_frac=args.tv_lumisphere_sparsity,\n",
    "                        ndc_coeffs=dset.ndc_coeffs)\n",
    "            if args.lambda_l2_sh > 0.0:\n",
    "                grid.inplace_l2_color_grad(grid.sh_data.grad,\n",
    "                        scaling=args.lambda_l2_sh)\n",
    "            if grid.use_background and (args.lambda_tv_background_sigma > 0.0 or args.lambda_tv_background_color > 0.0):\n",
    "                grid.inplace_tv_background_grad(grid.background_data.grad,\n",
    "                        scaling=args.lambda_tv_background_color,\n",
    "                        scaling_density=args.lambda_tv_background_sigma,\n",
    "                        sparse_frac=args.tv_background_sparsity,\n",
    "                        contiguous=args.tv_contiguous)\n",
    "            if args.lambda_tv_basis > 0.0:\n",
    "                tv_basis = grid.tv_basis()\n",
    "                loss_tv_basis = tv_basis * args.lambda_tv_basis\n",
    "                loss_tv_basis.backward()\n",
    "            #  print('nz density', torch.count_nonzero(grid.sparse_grad_indexer).item(),\n",
    "            #        ' sh', torch.count_nonzero(grid.sparse_sh_grad_indexer).item())\n",
    "            \n",
    "            if args.lambda_depth > 0.0:\n",
    "                grid.inplace_depth_grad(grid.density_data.grad,\n",
    "                                       scaling = args.lambda_depth)\n",
    "                \n",
    "\n",
    "            # Manual SGD/rmsprop step\n",
    "            if gstep_id >= args.lr_fg_begin_step:\n",
    "                grid.optim_density_step(lr_sigma, beta=args.rms_beta, optim=args.sigma_optim)\n",
    "                grid.optim_sh_step(lr_sh, beta=args.rms_beta, optim=args.sh_optim)\n",
    "            if grid.use_background:\n",
    "                grid.optim_background_step(lr_sigma_bg, lr_color_bg, beta=args.rms_beta, optim=args.bg_optim)\n",
    "            if gstep_id >= args.lr_basis_begin_step:\n",
    "                if grid.basis_type == svox2.BASIS_TYPE_3D_TEXTURE:\n",
    "                    grid.optim_basis_step(lr_basis, beta=args.rms_beta, optim=args.basis_optim)\n",
    "                elif grid.basis_type == svox2.BASIS_TYPE_MLP:\n",
    "                    optim_basis_mlp.step()\n",
    "                    optim_basis_mlp.zero_grad()\n",
    "\n",
    "    train_step()\n",
    "    gc.collect()\n",
    "    gstep_id_base += batches_per_epoch\n",
    "\n",
    "    #  ckpt_path = path.join(args.train_dir, f'ckpt_{epoch_id:05d}.npz')\n",
    "    # Overwrite prev checkpoints since they are very huge\n",
    "    if args.save_every > 0 and (epoch_id + 1) % max(\n",
    "            factor, args.save_every) == 0 and not args.tune_mode:\n",
    "        print('Saving', ckpt_path)\n",
    "        grid.save(ckpt_path)\n",
    "\n",
    "    if (gstep_id_base - last_upsamp_step) >= args.upsamp_every:\n",
    "        last_upsamp_step = gstep_id_base\n",
    "        if reso_id < len(reso_list) - 1:\n",
    "            print('* Upsampling from', reso_list[reso_id], 'to', reso_list[reso_id + 1])\n",
    "            if args.tv_early_only > 0:\n",
    "                print('turning off TV regularization')\n",
    "                args.lambda_tv = 0.0\n",
    "                args.lambda_tv_sh = 0.0\n",
    "            elif args.tv_decay != 1.0:\n",
    "                args.lambda_tv *= args.tv_decay\n",
    "                args.lambda_tv_sh *= args.tv_decay\n",
    "\n",
    "            reso_id += 1\n",
    "            use_sparsify = True\n",
    "            z_reso = reso_list[reso_id] if isinstance(reso_list[reso_id], int) else reso_list[reso_id][2]\n",
    "            grid.resample(reso=reso_list[reso_id],\n",
    "                    sigma_thresh=args.density_thresh,\n",
    "                    weight_thresh=args.weight_thresh / z_reso if use_sparsify else 0.0,\n",
    "                    dilate=2, #use_sparsify,\n",
    "                    cameras=resample_cameras if args.thresh_type == 'weight' else None,\n",
    "                    max_elements=args.max_grid_elements)\n",
    "\n",
    "            if grid.use_background and reso_id <= 1:\n",
    "                grid.sparsify_background(args.background_density_thresh)\n",
    "\n",
    "            if args.upsample_density_add:\n",
    "                grid.density_data.data[:] += args.upsample_density_add\n",
    "\n",
    "        if factor > 1 and reso_id < len(reso_list) - 1:\n",
    "            print('* Using higher resolution images due to large grid; new factor', factor)\n",
    "            factor //= 2\n",
    "            dset.gen_rays(factor=factor)\n",
    "            dset.shuffle_rays()\n",
    "\n",
    "    if gstep_id_base >= args.n_iters:\n",
    "        print('* Final eval and save')\n",
    "        eval_step()\n",
    "        global_stop_time = datetime.now()\n",
    "        secs = (global_stop_time - global_start_time).total_seconds()\n",
    "        timings_file = open(os.path.join(args.train_dir, 'time_mins.txt'), 'a')\n",
    "        timings_file.write(f\"{secs / 60}\\n\")\n",
    "        if not args.tune_nosave:\n",
    "            grid.save(ckpt_path)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "TODO",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTODO\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: TODO"
     ]
    }
   ],
   "source": [
    "assert False, \"TODO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29RICBe7B_im"
   },
   "source": [
    "# Рендерим результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "L_CobG6SGWfc"
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "FzdliYOWGWmW"
   },
   "outputs": [],
   "source": [
    "render_dir = PATH + \"/render\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "b-KFD-z9H5Bp"
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    dset_render = dset_test\n",
    "else:\n",
    "    dset_render = dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "67c9404f42de40febb7d575725130766",
      "58928c8ac4884017b1b64f1190a543b8",
      "12ba36689d634f62bc40873150ee2ad5",
      "314da65bdacd4fbbae5ae9ef9b578c7e",
      "8ee06e5eeb124750bbf46b0f348f867d",
      "3829be684a6747d48e58af0f6d1b688d",
      "d8382fd3d92b4b0cac94c068a20895d6",
      "c2fe7d5de0e04d448aa2775c8cfb1e15",
      "be71165e1c0145efb690c172e2745e90",
      "ed08435c0bf14afeacfce8e3bbf0643e",
      "60b335ebd0a54d0e83170765c4557138"
     ]
    },
    "executionInfo": {
     "elapsed": 21717,
     "status": "ok",
     "timestamp": 1644424619523,
     "user": {
      "displayName": "Артем Мельников",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg3u21bfj3xbUWHLdTdT6sP-k0huGdxWfq9GMsmJQ=s64",
      "userId": "12648836304799801100"
     },
     "user_tz": -180
    },
    "id": "O-3cpk9NCpGF",
    "outputId": "34aac8b3-c210-4f7f-bc24-4b52aed45db7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0aecfb4dcf44c389d1c9c4f49c9af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_images = dset_render.n_images\n",
    "    img_eval_interval = max(n_images // 100000, 1)\n",
    "    avg_psnr = 0.0\n",
    "    avg_ssim = 0.0\n",
    "    avg_lpips = 0.0\n",
    "    n_images_gen = 0\n",
    "    c2ws = dset_render.c2w.to(device=device)\n",
    "\n",
    "    frames = []\n",
    "    for img_id in tqdm(range(0, n_images, img_eval_interval)):\n",
    "        dset_h, dset_w = dset.get_image_size(img_id)\n",
    "        im_size = dset_h * dset_w\n",
    "        w = dset_w if args.crop == 1.0 else int(dset_w * args.crop)\n",
    "        h = dset_h if args.crop == 1.0 else int(dset_h * args.crop)\n",
    "\n",
    "        cam = svox2.Camera(c2ws[img_id],\n",
    "                           dset_render.intrins.get('fx', img_id),\n",
    "                           dset_render.intrins.get('fy', img_id),\n",
    "                           dset_render.intrins.get('cx', img_id) + (w - dset_w) * 0.5,\n",
    "                           dset_render.intrins.get('cy', img_id) + (h - dset_h) * 0.5,\n",
    "                           w, h,\n",
    "                           ndc_coeffs=dset.ndc_coeffs)\n",
    "        im = grid.volume_render_image(cam, use_kernel=True, return_raylen=args.ray_len)\n",
    "       \n",
    "        if args.ray_len:\n",
    "            minv, meanv, maxv = im.min().item(), im.mean().item(), im.max().item()\n",
    "            im = viridis_cmap(im.cpu().numpy())\n",
    "            cv2.putText(im, f\"{'%.4f' % minv} {'%.4f' % meanv} {'%.4f' % maxv}\", (10, 20),\n",
    "                        0, 0.5, [255, 0, 0])\n",
    "            im = torch.from_numpy(im).to(device=device)\n",
    "        im.clamp_(0.0, 1.0)\n",
    "\n",
    "        im_gt = dset_render.gt[img_id].to(device=device)\n",
    "        mse = (im - im_gt) ** 2 \n",
    "        mse_num : float = mse.mean().item()\n",
    "        psnr = -10.0 * math.log10(mse_num)\n",
    "        avg_psnr += psnr\n",
    "\n",
    "        img_path = path.join(render_dir, f'{\"%.04d\" % img_id}.png');\n",
    "        im = im.cpu().numpy()\n",
    "\n",
    "        im_gt = dset_render.gt[img_id].numpy()\n",
    "        im = np.concatenate([im_gt, im], axis=1)\n",
    "\n",
    "        im = (im * 255).astype(np.uint8)\n",
    "        if not args.no_imsave:\n",
    "            imageio.imwrite(img_path,im)\n",
    "        if not args.no_vid:\n",
    "            frames.append(im)\n",
    "\n",
    "        im = None\n",
    "        n_images_gen += 1\n",
    "\n",
    "    if not args.no_vid and len(frames):\n",
    "        vid_path = render_dir + '/compilation.mp4'\n",
    "        imageio.mimwrite(vid_path, frames, fps=30, macro_block_size=8)  # pip install imageio-ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e60df938b5945a49d549e04f4e3b5c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1015, 764) to (1024, 768) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "[swscaler @ 0x5b15140] Warning: data is not aligned! This can lead to a speed loss\n"
     ]
    }
   ],
   "source": [
    "# scrap this. c2w hard to modify to get right views(for now)\n",
    "\"\"\"\n",
    "cam = svox2.Camera(c2ws[0],\n",
    "                           dset.intrins.get('fx', 0),\n",
    "                           dset.intrins.get('fy', 0),\n",
    "                           dset.intrins.get('cx', 0) + (w - dset_w) * 0.5,\n",
    "                           dset.intrins.get('cy', 0) + (h - dset_h) * 0.5,\n",
    "                           w, h,\n",
    "                           ndc_coeffs=dset.ndc_coeffs)\n",
    "with torch.no_grad():\n",
    "    frames = []\n",
    "    for i in tqdm(range(round(360/5))):\n",
    "        \n",
    "        im = grid.volume_render_image(cam, use_kernel=True, return_raylen=args.ray_len)\n",
    "\n",
    "        im = im.cpu().numpy()\n",
    "        \n",
    "        im = (im * 255).astype(np.uint8)\n",
    "\n",
    "        img_path = path.join(render_dir, f'{\"%.04d\" % i}.png')\n",
    "        # imageio.imwrite(img_path,im)\n",
    "        frames.append(im)\n",
    "    if not args.no_vid and len(frames):\n",
    "        vid_path = render_dir + '/compilation.mp4'\n",
    "        imageio.mimwrite(vid_path, frames, fps=30, macro_block_size=8)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.tensorboard.writer.SummaryWriter at 0x7fae842dafd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMyStyw40GL4iZcxrEW1hHc",
   "collapsed_sections": [
    "29RICBe7B_im"
   ],
   "machine_shape": "hm",
   "mount_file_id": "1xVbS56Xn7PWR-z2iB35qPr2k7HxlB_Ny",
   "name": "coursework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "12ba36689d634f62bc40873150ee2ad5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2fe7d5de0e04d448aa2775c8cfb1e15",
      "max": 43,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_be71165e1c0145efb690c172e2745e90",
      "value": 43
     }
    },
    "314da65bdacd4fbbae5ae9ef9b578c7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed08435c0bf14afeacfce8e3bbf0643e",
      "placeholder": "​",
      "style": "IPY_MODEL_60b335ebd0a54d0e83170765c4557138",
      "value": " 43/43 [00:19&lt;00:00,  2.37it/s]"
     }
    },
    "3829be684a6747d48e58af0f6d1b688d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58928c8ac4884017b1b64f1190a543b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3829be684a6747d48e58af0f6d1b688d",
      "placeholder": "​",
      "style": "IPY_MODEL_d8382fd3d92b4b0cac94c068a20895d6",
      "value": "100%"
     }
    },
    "60b335ebd0a54d0e83170765c4557138": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "67c9404f42de40febb7d575725130766": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58928c8ac4884017b1b64f1190a543b8",
       "IPY_MODEL_12ba36689d634f62bc40873150ee2ad5",
       "IPY_MODEL_314da65bdacd4fbbae5ae9ef9b578c7e"
      ],
      "layout": "IPY_MODEL_8ee06e5eeb124750bbf46b0f348f867d"
     }
    },
    "8ee06e5eeb124750bbf46b0f348f867d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be71165e1c0145efb690c172e2745e90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c2fe7d5de0e04d448aa2775c8cfb1e15": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8382fd3d92b4b0cac94c068a20895d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ed08435c0bf14afeacfce8e3bbf0643e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
